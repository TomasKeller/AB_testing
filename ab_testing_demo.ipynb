{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://towardsdatascience.com/a-b-testing-design-execution-6cf9e27c6559"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what’s going to happen, we need to conduct an A/B test. In this article, we are going to focus on how we can execute our test programmatically and report the statistics behind it. \n",
    "\n",
    "Just before jumping into coding, there are two important points you need to think while designing and A/B test.\n",
    "- 1- What is your hypothesis?\n",
    "\n",
    "Going forward with the example above, our hypothesis is, test group will have more retention:\n",
    "Group A → Offer → Higher Retention\n",
    "Group B → No offer → Lower Retention\n",
    "This also helps us to test model accuracy as well. If group B’s retention rate is 50%, it clearly shows that our model is not working. The same applies to measure revenue coming from those users too.\n",
    "- 2- What is your success metric?\n",
    "\n",
    "In this case, we are going to check the retention rate of both groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programmatic A/B Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from __future__ import division\n",
    "\n",
    "from datetime import datetime, timedelta,date\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hv = pd.DataFrame()\n",
    "df_hv['customer_id'] = np.array([count for count in range(20000)])\n",
    "df_hv['segment'] = np.array(['high-value' for _ in range(20000)])\n",
    "df_hv['group'] = 'control'\n",
    "df_hv.loc[df_hv.index<10000,'group'] = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, purchase count should be a Poisson distribution. There will be customers with no purchase and we will have less customers with high purchase counts. Let’s use numpy.random.poisson() for doing that and assign different distributions to test and control group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hv.loc[df_hv.group == 'test', 'purchase_count'] = np.random.poisson(0.6, 10000)\n",
    "df_hv.loc[df_hv.group == 'control', 'purchase_count'] = np.random.poisson(0.5, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we applied an offer to 50% of high-value users and observed their purchases in a given period. Best way to visualize it to check the densities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_count</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       purchase_count    group\n",
       "0                 1.0     test\n",
       "1                 1.0     test\n",
       "2                 0.0     test\n",
       "3                 0.0     test\n",
       "4                 0.0     test\n",
       "...               ...      ...\n",
       "19995             0.0  control\n",
       "19996             0.0  control\n",
       "19997             1.0  control\n",
       "19998             0.0  control\n",
       "19999             1.0  control\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results = df_hv[df_hv.group == 'test'].purchase_count\n",
    "control_results = df_hv[df_hv.group == 'control'].purchase_count\n",
    "\n",
    "hist_data = [test_results, control_results]\n",
    "\n",
    "group_labels = ['test', 'control']\n",
    "\n",
    "\n",
    "\n",
    "#sns.histplot(data=dv_hv, x=\"purchase_count\", hue=\"group\")\n",
    "df_hv[['purchase_count','group']]#.plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats \n",
    "def eval_test(test_results,control_results):\n",
    "    test_result = stats.ttest_ind(test_results, control_results)\n",
    "    if test_result[1] < 0.05:\n",
    "        print('result is significant')\n",
    "    else:\n",
    "        print('result is not significant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result is significant\n"
     ]
    }
   ],
   "source": [
    "eval_test(test_results, control_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks great but unfortunately, it is not that simple. If you select a biased test group, your results will be statistically significant by default. As an example, if we allocate more high-value customer to test group and more low-value customers to control group, then our experiment becomes a failure from the beginning. That’s why selecting the group is the key to a healthy A/B test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Test & Control Groups\n",
    "\n",
    "The most common approach to select test & control groups is random sampling. Let’s see how we can do it programmatically. We are going to start with creating the dataset first. In this version, it will have 20k high-value and 80k low-value customers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create hv segment\n",
    "df_hv = pd.DataFrame()\n",
    "df_hv['customer_id'] = np.array([count for count in range(20000)])\n",
    "df_hv['segment'] = np.array(['high-value' for _ in range(20000)])\n",
    "df_hv['prev_purchase_count'] = np.random.poisson(0.9, 20000)\n",
    "df_lv = pd.DataFrame()\n",
    "df_lv['customer_id'] = np.array([count for count in range(20000,100000)])\n",
    "df_lv['segment'] = np.array(['low-value' for _ in range(80000)])\n",
    "df_lv['prev_purchase_count'] = np.random.poisson(0.3, 80000)\n",
    "df_customers = pd.concat([df_hv,df_lv],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_customers.sample(frac=0.9)\n",
    "df_control = df_customers[~df_customers.customer_id.isin(df_test.customer_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we extracted 90% of the whole group and labeled it as test. But there is a small problem that can ruin our experiment. If you have significantly different multiple groups in your dataset (in this case, high-value & low-value), better to do random sampling separately. Otherwise, we can’t guarantee that the ratio of high-value to low-value is the same for test and control group.\n",
    "\n",
    "To ensure creating test and control groups correctly, we need to apply the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_hv = df_customers[df_customers.segment == 'high-value'].sample(frac=0.9)\n",
    "df_test_lv = df_customers[df_customers.segment == 'low-value'].sample(frac=0.9)\n",
    "df_test = pd.concat([df_test_hv,df_test_lv],axis=0)\n",
    "df_control = df_customers[~df_customers.customer_id.isin(df_test.customer_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-way ANOVA\n",
    "Let’s assume we are testing 2+ variants on same groups (i.e 2 different offers and no-offer to low-value high-value customers). Then we need to apply one-way ANOVA for evaluating our experiment. Let’s start from creating our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create hv segment\n",
    "df_hv = pd.DataFrame()\n",
    "df_hv['customer_id'] = np.array([count for count in range(30000)])\n",
    "df_hv['segment'] = np.array(['high-value' for _ in range(30000)])\n",
    "df_hv['group'] = 'A'\n",
    "df_hv.loc[df_hv.index>=10000,'group'] = 'B' \n",
    "df_hv.loc[df_hv.index>=20000,'group'] = 'C' \n",
    "\n",
    "df_hv.loc[df_hv.group == 'A', 'purchase_count'] = np.random.poisson(0.4, 10000)\n",
    "df_hv.loc[df_hv.group == 'B', 'purchase_count'] = np.random.poisson(0.6, 10000)\n",
    "df_hv.loc[df_hv.group == 'C', 'purchase_count'] = np.random.poisson(0.2, 10000)\n",
    "\n",
    "a_stats = df_hv[df_hv.group=='A'].purchase_count\n",
    "b_stats = df_hv[df_hv.group=='B'].purchase_count\n",
    "c_stats = df_hv[df_hv.group=='C'].purchase_count\n",
    "\n",
    "hist_data = [a_stats, b_stats, c_stats]\n",
    "\n",
    "group_labels = ['A', 'B','C']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_anova_test(a_stats,b_stats,c_stats):\n",
    "    test_result = stats.f_oneway(a_stats, b_stats, c_stats)\n",
    "    if test_result[1] < 0.05:\n",
    "        print('result is significant')\n",
    "    else:\n",
    "        print('result is not significant')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result is significant\n"
     ]
    }
   ],
   "source": [
    "one_anova_test(a_stats, b_stats, c_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-way ANOVA\n",
    "Let’s say we are doing the same test on both high-value and low-value customers. In this case, we need to apply two-way ANOVA. We are going to create our dataset again and build our evaluation method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create hv segment\n",
    "df_hv = pd.DataFrame()\n",
    "df_hv['customer_id'] = np.array([count for count in range(20000)])\n",
    "df_hv['segment'] = np.array(['high-value' for _ in range(20000)])\n",
    "df_hv['group'] = 'control'\n",
    "df_hv.loc[df_hv.index<10000,'group'] = 'test' \n",
    "df_hv.loc[df_hv.group == 'control', 'purchase_count'] = np.random.poisson(0.6, 10000)\n",
    "df_hv.loc[df_hv.group == 'test', 'purchase_count'] = np.random.poisson(0.8, 10000)\n",
    "\n",
    "\n",
    "df_lv = pd.DataFrame()\n",
    "df_lv['customer_id'] = np.array([count for count in range(20000,100000)])\n",
    "df_lv['segment'] = np.array(['low-value' for _ in range(80000)])\n",
    "df_lv['group'] = 'control'\n",
    "df_lv.loc[df_lv.index<40000,'group'] = 'test' \n",
    "df_lv.loc[df_lv.group == 'control', 'purchase_count'] = np.random.poisson(0.2, 40000)\n",
    "df_lv.loc[df_lv.group == 'test', 'purchase_count'] = np.random.poisson(0.3, 40000)\n",
    "\n",
    "df_customers = pd.concat([df_hv,df_lv],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf \n",
    "from statsmodels.stats.anova import anova_lm\n",
    "model = smf.ols(formula='purchase_count ~ segment + group ', data=df_customers).fit()\n",
    "aov_table = anova_lm(model, typ=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Size Calculation\n",
    "To calculate the required sample size, first we need to understand two concepts:\n",
    "\n",
    "- Effect size: this represents the magnitude of difference between averages of test and control group. It is the variance in averages between test and control groups divided by the standard deviation of the control.\n",
    "- Power: this refers to the probability of finding a statistical significance in your test. To calculate the sample size, 0.8 is the common value that is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats import power\n",
    "ss_analysis = power.TTestIndPower()\n",
    "#create hv segment\n",
    "df_hv = pd.DataFrame()\n",
    "df_hv['customer_id'] = np.array([count for count in range(20000)])\n",
    "df_hv['segment'] = np.array(['high-value' for _ in range(20000)])\n",
    "df_hv['prev_purchase_count'] = np.random.poisson(0.7, 20000)\n",
    "purchase_mean = df_hv.prev_purchase_count.mean()\n",
    "purchase_std = df_hv.prev_purchase_count.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the average of purchases (purchase_mean) is 0.7 and the standard deviation (purchase_std) is 0.84.\n",
    "\n",
    "Let’s say we want to increase the purchase_mean to 0.75 in this experiment. We can calculate the effect size like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_size = (0.75 - purchase_mean)/purchase_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, the sample size calculation is quite simple:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3158.6183498138957\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "power = 0.8\n",
    "ratio = 1\n",
    "ss_result = ss_analysis.solve_power(effect_size=effect_size, power=power,alpha=alpha, ratio=ratio , nobs1=None) \n",
    "print(ss_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Alpha is the threshold for statistical significance (5%) and \n",
    "- our ratio of test and control sample sizes are 1 (equal). \n",
    "- As a result, our required sample size is (output of ss_result) 4868."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sample_size(c_data, column_name, target,ratio):\n",
    "    value_mean = c_data[column_name].mean()\n",
    "    value_std = c_data[column_name].std()\n",
    "    \n",
    "    value_target = value_mean * target\n",
    "    \n",
    "    effect_size = (value_target - value_mean)/value_std\n",
    "    \n",
    "    power = 0.8\n",
    "    alpha = 0.05\n",
    "    ss_result = ss_analysis.solve_power(effect_size=effect_size, power=power,alpha=alpha, ratio=ratio , nobs1=None) \n",
    "    print(int(ss_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this function, \n",
    "- we need to provide our dataset, \n",
    "- the column_name that represents the value (purchase_count in our case), \n",
    "- our target mean (0.75 was our target in the previous example) and \n",
    "- the ratio.\n",
    "\n",
    "In the dataset above, let’s assume we want to increase purchase count mean by 5% and we will keep the sizes of both groups the same:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9243\n"
     ]
    }
   ],
   "source": [
    "calculate_sample_size(df_hv, 'prev_purchase_count', 1.05,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
